{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853e6210-68af-4c9b-b634-6056323f8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "# metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85e4b714-2d8b-4c55-a919-bea346379dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Difference:\n",
    "\n",
    "# Euclidean distance calculates the straight-line distance between two points, while Manhattan distance calculates the sum \n",
    "# of absolute differences.\n",
    "# Euclidean distance is sensitive to outliers and noisy data, while Manhattan distance is more robust.\n",
    "\n",
    "# Impact on KNN Performance:\n",
    "# Choice of distance metric affects performance, with Euclidean distance suitable for continuous features and Gaussian \n",
    "# distributions, and Manhattan distance suitable for categorical/ordinal features and noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a47ffa28-86de-4a1a-af60-37af5756bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "# used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b45767c-b42e-4fa1-bfb4-4b75dae03c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation: Evaluate performance for different ùëò values and select the best.\n",
    "# Grid Search: Test a range of ùëò values and choose the one with the best score.\n",
    "# Elbow Method: Plot performance metrics versus ùëò and find the point where improvements level off.\n",
    "# Leave-One-Out Cross-Validation (LOOCV): Use each data point as a validation set to determine the best k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9cb0301-eada-4ad2-9029-ad14de0dbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "# what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b93712d-b2f3-470a-b944-21f06b36760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance:\n",
    "# Use: Effective when features are on similar scales and when the relationship between features is linear.\n",
    "# Performance: Sensitive to differences in scale and outliers.\n",
    "\n",
    "# Manhattan Distance:\n",
    "# Use: Suitable when features have different scales or when you want to avoid the influence of outliers.\n",
    "# Performance: Robust to feature scales and can be better for high-dimensional data.\n",
    "\n",
    "# Choosing Metrics:\n",
    "# Use Euclidean when features are scaled similarly and you expect linear relationships.\n",
    "# Use Manhattan for high-dimensional data or when features have varying scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73e57bfb-45b7-411b-907b-1d24063ba717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "# the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "# model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc343667-58f6-4853-9f29-5697a9cdb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Hyperparameters in KNN:\n",
    "# k (Number of Neighbors): Controls the number of nearest neighbors to consider.\n",
    "# Distance Metric: Chooses the distance calculation method (e.g., Euclidean, Manhattan, Minkowski).\n",
    "# Weighting: Determines how to weight the neighbors' contributions (e.g., uniform, distance-based)\n",
    "\n",
    "# How Hyperparameters Affect Performance:\n",
    "# k: Affects the model's bias-variance tradeoff. Small k values can lead to overfitting, while large k values can lead to \n",
    "# underfitting.\n",
    "# Distance Metric: Influences the model's sensitivity to outliers and noisy data.\n",
    "# Weighting: Impacts the model's ability to handle imbalanced datasets.\n",
    "\n",
    "# Tuning Hyperparameters:\n",
    "# Grid Search: Try different combinations of hyperparameters and evaluate the model's performance.\n",
    "# Random Search: Randomly sample hyperparameter combinations and evaluate the model's performance.\n",
    "\n",
    "# Example:\n",
    "# Suppose we're building a KNN classifier to predict customer churn. We want to tune the hyperparameters to improve the\n",
    "# model's accuracy\n",
    "\n",
    "# nitial Hyperparameters:\n",
    "# k = 5\n",
    "# Distance Metric = Euclidean\n",
    "# Weighting = Uniform\n",
    "\n",
    "# Tuning:\n",
    "# Try k = 3, 5, 7, 9\n",
    "# Try Distance Metric = Manhattan, Minkowski\n",
    "# Try Weighting = Distance-based\n",
    "\n",
    "# Best Hyperparameters:\n",
    "# k = 7\n",
    "# Distance Metric = Manhattan\n",
    "# Weighting = Distance-based\n",
    "# Improved Accuracy: 85% ‚Üí 92%\n",
    "\n",
    "# By tuning the hyperparameters, we improved the model's accuracy from 85% to 92%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d578931-cb1c-4900-974e-e9ee34464655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "# techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afafb5ef-f0ac-4175-9bc0-464bedfdfb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of Training Set Size: Small training sets can lead to overfitting, while large training sets can suffer from the \n",
    "# curse of dimensionality.\n",
    "\n",
    "# Optimizing Training Set Size: Techniques include data augmentation, data sampling, active learning, transfer learning,\n",
    "# data pruning, cross-validation, and bootstrap sampling.\n",
    "\n",
    "# Techniques to Optimize Training Set Size: Use methods like hold-out, learning curve analysis, and validation curve analysis\n",
    "# to determine the optimal training set size.\n",
    "\n",
    "# For example, to optimize the training set size for a KNN classifier predicting customer churn, we can apply data \n",
    "# augmentation, active learning, and cross-validation to find the best training set size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76d4e1af-6b9a-4a3d-8d1a-283027a8a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "# overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "700158ed-06d3-4608-8117-a2a778fcc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawback: KNN is slow with large datasets and high-dimensional features.\n",
    "\n",
    "# Example: Imagine using KNN to classify thousands of images. Each time you want to classify a new image, KNN must compare\n",
    "# it to all the stored images, which can be very slow.\n",
    "\n",
    "# Solution: Use a KD-Tree to organize the images in a way that makes these comparisons faster, or reduce the number of image\n",
    "# features with techniques like PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20b888-bc87-4544-b67a-d6bf6ce29f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7850f4b-1c89-4cfb-82a5-a8d1837d52ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8d030-0ea3-4018-a12b-f5d8822724e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d5bf4-c534-4fee-8af4-39c4cb2d27a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc1bdc-4882-499b-88cd-80f990620ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32a196-35a0-48f2-b433-45a3f852d856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9227d8-f9d4-4b06-b7c5-f1acab5e3805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737d4c4-e46a-4472-a5ee-fc6820dde319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
