{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c7be37-e476-40d2-a905-63d7e628bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach?\n",
    "# Explain with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149442a2-d982-41c3-8f11-051ceed50107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalues: Scalars that represent how much a matrix stretches or shrinks a vector.\n",
    "# Eigenvectors: Non-zero vectors that, when transformed by a matrix, result in a scaled version of themselves.\n",
    "\n",
    "# Eigen-Decomposition:\n",
    "\n",
    "# A = Q Λ Q^(-1), where:\n",
    "\n",
    "# A is the original matrix\n",
    "# Q is an orthogonal matrix (i.e., Q^T Q = I)\n",
    "# Λ is a diagonal matrix containing the eigenvalues\n",
    "# Q^(-1) is the inverse of Q\n",
    "\n",
    "# A = | 2  0 |\n",
    "#     | 0  3 |\n",
    "    \n",
    "# This matrix scales the x-axis by a factor of 2 and the y-axis by a factor of 3.\n",
    "\n",
    "# The eigenvalues and eigenvectors of A are:\n",
    "\n",
    "# Eigenvalues: λ1 = 2 and λ2 = 3\n",
    "# Eigenvectors: v1 = [1, 0] and v2 = [0, 1]\n",
    "# The eigenvectors v1 and v2 are scaled by the eigenvalues λ1 and λ2, respectively, when transformed by A.   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b8eed0-a284-4590-9fb6-17bed3463d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is eigen decomposition and what is its significance in linear algebra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61b8d53-7889-4004-a29c-260a480c233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigen-Decomposition:\n",
    "\n",
    "# A way to express a matrix as A = Q Λ Q^(-1), where Q is an orthogonal matrix, Λ is a diagonal matrix of eigenvalues,\n",
    "# and Q^(-1) is the inverse of Q.\n",
    "\n",
    "# Significance:\n",
    "\n",
    "# Diagonalization of matrices\n",
    "# Stability analysis\n",
    "# Dimensionality reduction (e.g., PCA)\n",
    "# Image compression\n",
    "# Markov chain analysis\n",
    "# Data analysis\n",
    "# Machine learning (e.g., PCA, LLE, t-SNE)\n",
    "# Signal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ce897c-e195-416f-ad89-3e0e771fa650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the\n",
    "# Eigen-Decomposition approach? Provide a brief proof to support your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baef44b9-fddf-4419-a9ff-ccb4920ec124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions for Diagonalizability:\n",
    "#     A square matrix A is diagonalizable using the Eigen-Decomposition approach if and only if it satisfies the following\n",
    "#     conditions:\n",
    "        \n",
    "#   A has n linearly independent eigenvectors, where n is the size of the matrix.\n",
    "#   A has n distinct eigenvalues.\n",
    "\n",
    "# Brief Proof:\n",
    "    \n",
    "# Let's assume A is a square matrix of size n x n. We want to show that if A has n linearly independent eigenvectors and n \n",
    "# distinct eigenvalues, then it is diagonalizable.\n",
    "\n",
    "# Step 1: Since A has n linearly independent eigenvectors, we can form a matrix Q whose columns are these eigenvectors. By \n",
    "# definition, Q is an invertible matrix (since its columns are linearly independent).\n",
    "\n",
    "# Step 2: Let Λ be a diagonal matrix containing the n distinct eigenvalues of A. We can write:\n",
    "\n",
    "# AQ = QΛ\n",
    "\n",
    "# Step 3: Multiply both sides by Q^(-1):\n",
    "\n",
    "# A = QΛQ^(-1)\n",
    "\n",
    "# This is the Eigen-Decomposition of A. Since Q is invertible, we can conclude that A is diagonalizable.\n",
    "\n",
    "# Converse: If A is diagonalizable, then it can be written as A = QΛQ^(-1) for some invertible matrix Q and diagonal\n",
    "# matrix Λ. This implies that A has n linearly independent eigenvectors (columns of Q) and n distinct eigenvalues \n",
    "# (diagonal elements of Λ).\n",
    "\n",
    "# Therefore, the conditions are both necessary and sufficient for a square matrix to be diagonalizable using the \n",
    "# Eigen-Decomposition approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2c7ce3-f2b8-4942-a08f-2b6c4a2f2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach?\n",
    "# How is it related to the diagonalizability of a matrix? Explain with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb42483-5201-47b6-bef2-adaa0e9f8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Spectral Theorem states that a symmetric matrix is diagonalizable, and its eigenvectors can be chosen to be orthogonal\n",
    "# to each other.\n",
    "\n",
    "# Key Implications:\n",
    "\n",
    "# Guarantees diagonalizability for symmetric matrices.\n",
    "# Orthogonality of eigenvectors simplifies calculations and application\n",
    "\n",
    "# Example:\n",
    "# A symmetric matrix A can be diagonalized using the Spectral Theorem, ensuring orthogonal eigenvectors and a diagonal\n",
    "# matrix Λ containing its eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6077730e-d9e3-4f0d-b189-330d33f6406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. How do you find the eigenvalues of a matrix and what do they represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93685e9e-931b-49ee-b649-611892068657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Eigenvalues:\n",
    "# Characteristic Equation: |A - λI| = 0\n",
    "# Eigenvalue Decomposition: Use libraries like NumPy or MATLAB\n",
    "# Power Iteration: An iterative algorithm for dominant eigenvalue and eigenvector\n",
    "\n",
    "# Eigenvalue Interpretation:\n",
    "# Positive: Stretching or expansion\n",
    "# Negative: Shrinking or compression\n",
    "# Zero: No change or collapse\n",
    "# Large: Significant changes or dominant directions\n",
    "# Small: Minor changes or less important directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "478707c3-e242-42f6-819c-64c76d4f8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. What are eigenvectors and how are they related to eigenvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "540d1d5f-dee8-4f40-96b9-b7b2ffb66301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvectors:\n",
    "# An eigenvector is a non-zero vector that, when transformed by a linear transformation (represented by a matrix), results \n",
    "# in a scaled version of itself. In other words, if we multiply an eigenvector by a matrix, the resulting vector is a scalar\n",
    "# multiple of the original eigenvector.\n",
    "\n",
    "# Eigenvalues:\n",
    "# An eigenvalue is a scalar that represents the amount of scaling applied to an eigenvector when it is transformed by a \n",
    "# linear transformation. In other words, it is the factor by which the eigenvector is stretched or shrunk.\n",
    "\n",
    "# Relationship between Eigenvectors and Eigenvalues:\n",
    "\n",
    "# The relationship between eigenvectors and eigenvalues can be represented by the following equation:\n",
    "\n",
    "# Ax = λx\n",
    "\n",
    "# Where:\n",
    "\n",
    "# A is the matrix representing the linear transformation\n",
    "# x is the eigenvector\n",
    "# λ is the eigenvalue\n",
    "# This equation states that when the matrix A is multiplied by the eigenvector x, the result is a scaled version of x, where the scaling factor is the eigenvalue λ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e2e91f-93a2-4a11-a612-23f26af5ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "910e1887-2e27-4e90-8e57-cb9e78d148f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric Interpretation of Eigenvectors:\n",
    "# Eigenvectors represent the directions in which a linear transformation stretches or compresses. They are the directions in \n",
    "# which the transformation acts independently, without changing direction.\n",
    "\n",
    "# Imagine a rubber sheet that is stretched or compressed by a linear transformation. The eigenvectors represent the \n",
    "# directions in which the sheet is stretched or compressed, while the eigenvalues represent the amount of stretching or \n",
    "# compressing\n",
    "\n",
    "# Geometric Interpretation of Eigenvalues:\n",
    "# Eigenvalues represent the amount of scaling applied to each eigenvector direction. They indicate how much the \n",
    "# transformation stretches or compresses the eigenvector.\n",
    "\n",
    "# In the rubber sheet analogy, the eigenvalues represent the amount of stretching or compressing in each direction. If an \n",
    "# eigenvalue is greater than 1, the transformation stretches the eigenvector in that direction. If an eigenvalue is less \n",
    "# than 1, the transformation compresses the eigenvector in that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1172f428-55d6-4a7c-8ce5-d57ead8b72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. What are some real-world applications of eigen decomposition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb4232a-e94a-48d6-9837-965dc82404bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Compression: \n",
    "#     Eigen decomposition is used in image compression algorithms like PCA (Principal Component Analysis) to reduce the\n",
    "#     dimensionality of images and retain the most important features.\n",
    "    \n",
    "# Face Recognition: \n",
    "#     Eigenfaces, a technique based on eigen decomposition, is used in face recognition systems to identify individuals by\n",
    "#     extracting the most important features from facial images.\n",
    "    \n",
    "# Data Analysis: \n",
    "#     Eigen decomposition is used in data analysis to identify patterns, reduce dimensionality, and visualize high-dimensional\n",
    "#     data.\n",
    "    \n",
    "# Recommendation Systems: \n",
    "#     Eigen decomposition is used in recommendation systems to identify latent factors and provide personalized recommendations\n",
    "#     to users.\n",
    "    \n",
    "# Natural Language Processing (NLP): \n",
    "#     Eigen decomposition is used in NLP to analyze text data, identify topics, and perform sentiment analysis.\n",
    "    \n",
    "# Signal Processing: \n",
    "#     Eigen decomposition is used in signal processing to filter out noise, extract features, and analyze signals.\n",
    "    \n",
    "# Machine Learning: \n",
    "#     Eigen decomposition is used in machine learning to perform dimensionality reduction, feature extraction, and anomaly\n",
    "#     detection.\n",
    "    \n",
    "# Computer Vision: \n",
    "#     Eigen decomposition is used in computer vision to perform object recognition, tracking, and 3D\n",
    "# reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352a3787-86d3-4550-b4bb-d1cdacdcfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860019cf-bfaf-43bc-99c3-a3e7595eb2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, a matrix can have more than one set of eigenvectors and eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4950648e-f188-46cb-88c3-b826f3425d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning?\n",
    "# Discuss at least three specific applications or techniques that rely on Eigen-Decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebb1c0a1-e4e6-4506-9826-bbcd323d7afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigen-Decomposition is a key technique in data analysis and machine learning, used in various applications:\n",
    "\n",
    "# Principal Component Analysis (PCA): PCA reduces the dimensionality of data by using eigenvectors of the covariance matrix \n",
    "# to find directions of maximum variance, aiding in tasks like image compression and noise reduction.\n",
    "\n",
    "# Spectral Clustering: This technique uses Eigen-Decomposition of a similarity matrix to cluster data in a lower-dimensional\n",
    "# space, useful in complex data structures like image segmentation and social network analysis.\n",
    "\n",
    "# Eigenfaces for Face Recognition: Eigenfaces are derived through Eigen-Decomposition of facial image data, enabling \n",
    "# effective face recognition by identifying key facial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd434f-7af6-436e-a6d8-8512ef44c03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be5376-d56c-45f8-a60f-964684cce02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fca9d-cf76-4061-8935-2c9b8a913c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
