{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd3b812-dc1c-454c-8e1f-ff5644be215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b0657c-5c79-4dcf-9109-b1d30c236bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' theorem is a mathematical formula that helps update the probability of an event (A) based on new information (B). \n",
    "# It's like refining your guess about something after getting more data.\n",
    "\n",
    "# Formula:\n",
    "\n",
    "# P(A|B) = P(B|A) * P(A) / P(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb473d0c-6cf7-4593-9e0f-8769355a295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82127d47-a4e5-4da7-8ccb-fe66eeb686a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "# Where:\n",
    "\n",
    "# P(A|B) is the posterior probability of event A occurring given that event B has occurred.\n",
    "# P(B|A) is the likelihood of event B occurring given that event A has occurred.\n",
    "# P(A) is the prior probability of event A occurring.\n",
    "# P(B) is the prior probability of event B occurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bab2aab-a705-4f38-b03c-c94e3dfa68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad81328-352e-4c20-9a8f-005ed8320fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning: Bayes' theorem is used in machine learning algorithms, such as Naive Bayes, to classify data and make predictions.\n",
    "\n",
    "# Medical Diagnosis: Doctors use Bayes' theorem to update the probability of a disease diagnosis based on test results and patient symptoms.\n",
    "\n",
    "# Spam Filtering: Email providers use Bayes' theorem to determine the probability of an email being spam based on its content and sender.\n",
    "\n",
    "# Quality Control: Manufacturers use Bayes' theorem to update the probability of a product being defective based on inspection results.\n",
    "\n",
    "# Finance: Bayes' theorem is used in finance to update the probability of a stock's performance based on new market data.\n",
    "\n",
    "# Image Recognition: Bayes' theorem is used in image recognition systems to update the probability of an image belonging to a particular class (e.g., dog or cat).\n",
    "\n",
    "# Natural Language Processing: Bayes' theorem is used in NLP to update the probability of a word or phrase belonging to a particular language or context.\n",
    "\n",
    "# Risk Assessment: Bayes' theorem is used to update the probability of a risk event occurring based on new data and evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b99df69-a396-4f79-974f-d8c23b3e8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d393175-e38e-4ef2-8c71-ff86e68048bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To choose the right Naive Bayes classifier:\n",
    "\n",
    "# Gaussian Naive Bayes: Use for continuous features that follow a normal distribution.\n",
    "\n",
    "# Multinomial Naive Bayes: Use for discrete features representing counts or frequencies.\n",
    "\n",
    "# Bernoulli Naive Bayes: Use for binary features indicating the presence or absence of something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e597a89-804c-4322-9116-edd6c1da3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Assignment:\n",
    "# You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "# Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "# each feature value for each class:\n",
    "# Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "# A 3 3 4 4 3 3 3\n",
    "# B 2 2 1 2 2 2 3\n",
    "# Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "# to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "463a001a-e448-46e2-bae7-bf65292dfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the prior probabilities\n",
    "# Since we assume equal prior probabilities for each class, we have:\n",
    "# P(A) = P(B) = 0.5\n",
    "\n",
    "# Step 2: Calculate the likelihood probabilities\n",
    "# For each feature, we need to calculate the likelihood probabilities given the class. We'll use the frequency table to \n",
    "# estimate these probabilities.\n",
    "\n",
    "# Feature X1\n",
    "# P(X1=3 | A) = 4/10 = 0.4 (since 4 out of 10 instances of class A have X1=3) P(X1=3 | B) = 1/5 = 0.2 (since 1 out of 5\n",
    "# instances of class B have X1=3)\n",
    "\n",
    "# Feature X2\n",
    "# P(X2=4 | A) = 3/10 = 0.3 (since 3 out of 10 instances of class A have X2=4) P(X2=4 | B) = 3/5 = 0.6 \n",
    "# (since 3 out of 5 instances of class B have X2=4)\n",
    "\n",
    "# Step 3: Calculate the posterior probabilities\n",
    "# Using Bayes' theorem, we'll calculate the posterior probabilities for each class:\n",
    "# P(A | X1=3, X2=4) = P(X1=3 | A) * P(X2=4 | A) * P(A) / Evidence = 0.4 * 0.3 * 0.5 / Evidence\n",
    "# P(B | X1=3, X2=4) = P(X1=3 | B) * P(X2=4 | B) * P(B) / Evidence = 0.2 * 0.6 * 0.5 / Evidence\n",
    "\n",
    "# Step 4: Normalize the posterior probabilities\n",
    "# We need to normalize the posterior probabilities to ensure they add up to 1:\n",
    "# Evidence = P(X1=3, X2=4) = P(X1=3, X2=4 | A) * P(A) + P(X1=3, X2=4 | B) * P(B) = (0.4 * 0.3 * 0.5) + (0.2 * 0.6 * 0.5) = 0.12\n",
    "# Now, normalize the posterior probabilities:\n",
    "# P(A | X1=3, X2=4) = 0.4 * 0.3 * 0.5 / 0.12 ≈ 0.5 P(B | X1=3, X2=4) = 0.2 * 0.6 * 0.5 / 0.12 ≈ 0.5\n",
    "\n",
    "# Step 5: Make a prediction\n",
    "# Since both posterior probabilities are equal, we can't make a definitive prediction. However, in practice, we often choose \n",
    "# the class with the highest posterior probability. In this case, we can predict that the new instance belongs to either \n",
    "# class A or B with equal probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb983da-c495-46e8-a348-adb7631a2e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93f6d4-d426-49e7-b2a8-19810eb6637d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6bcc4b-7e36-40da-a4ec-1cca16aba705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa87121-2352-4ae5-a318-7afead0abe53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27614919-95f1-4101-9741-531be4e49891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe94fb3-433c-4a3c-8f63-3b616026873c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
