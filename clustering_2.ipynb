{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96124f51-34ac-4bb4-bc03-a3277a0c638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1220a247-c22e-4a3e-9691-3c4f84015f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering is a type of unsupervised machine learning algorithm that groups data points into clusters based on\n",
    "# their similarities. It is called \"hierarchical\" because it creates a hierarchy of clusters, where each cluster is a subset \n",
    "# of the previous one. This algorithm does not require a fixed number of clusters as input, unlike K-Means clustering.\n",
    "\n",
    "# How Hierarchical Clustering Works:\n",
    "    \n",
    "# Start with each data point as its own cluster: Each data point is initially considered a separate cluster.\n",
    "# Merge or split clusters: The algorithm iteratively merges or splits clusters based on their similarity or dissimilarity.\n",
    "# Create a hierarchy: The algorithm creates a hierarchy of clusters, where each cluster is a subset of the previous one.\n",
    "# Stop when a stopping criterion is met: The algorithm stops when a stopping criterion is met, such as a maximum number of\n",
    "# clusters or a minimum similarity threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf9819b-6156-4220-b521-6b1683b92b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03179dd4-24d2-43dc-837f-15209d21bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Agglomerative Clustering\n",
    "# Starts with individual data points: Each data point is initially considered a separate cluster.\n",
    "# Merges clusters: The algorithm iteratively merges the closest clusters until a stopping criterion is met.\n",
    "# Bottom-up approach: Agglomerative clustering is a bottom-up approach, where individual data points are gradually merged \n",
    "# into larger clusters.\n",
    "# Example: Single Linkage, Complete Linkage, Average Linkage, and Ward's Linkage are all agglomerative clustering algorithms.\n",
    "\n",
    "# 2. Divisive Clustering\n",
    "# Starts with a single cluster: All data points are initially considered a single cluster.\n",
    "# Splits clusters: The algorithm iteratively splits the cluster into smaller sub-clusters until a stopping criterion is met.\n",
    "# Top-down approach: Divisive clustering is a top-down approach, where a single cluster is gradually divided into smaller\n",
    "# sub-clusters.\n",
    "# Example: DIANA (Divisive Analysis Clustering) is a divisive clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eec552c-6cd1-46a1-94bf-6fb77882be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the\n",
    "# common distance metrics used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a168a5e-91c3-4f07-93b0-5b2f5729fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance Metrics measure the proximity between individual data points or clusters.\n",
    "# Linkage Methods determine how to combine clusters based on the chosen distance metric.\n",
    "\n",
    "# Common distance metrics used:\n",
    "#     1. Euclidean Distance (L2 Distance):\n",
    "#     2. Manhattan Distance (L1 Distance):\n",
    "#     4. Cosine Distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a6dd8f-5d7a-44d2-bc4b-9ed044a58e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some\n",
    "# common methods used for this purpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8d0ded-15f9-43bc-a889-36d6359e1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the optimal number of clusters in hierarchical clustering is a challenging task, as there is no universally\n",
    "# accepted method. However, here are some common methods used to determine the optimal number of clusters:\n",
    "\n",
    "# 1. Visual Inspection of the Dendrogram:\n",
    "# 2. Cutting the Dendrogram at a Specific Height:\n",
    "# 3. Silhouette Analysis:\n",
    "# 4. Elbow Method:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f9c2a3-292c-4e03-bbe8-b2d54e943247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c5ff92-d25f-4501-9907-c7565fd7c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dendrogram is a tree-like diagram that illustrates the hierarchical structure of clusters in a dataset. It is a\n",
    "# graphical representation of the clustering process, showing how the clusters are merged or split at each step\n",
    "\n",
    "# Components of a Dendrogram:\n",
    "#     Nodes: Represent individual data points or clusters.\n",
    "#     Edges: Connect nodes to form clusters.\n",
    "#     Height: The vertical axis represents the distance or similarity between clusters.\n",
    "#     Leaf nodes: The bottom-most nodes, representing individual data points.\n",
    "    \n",
    "# How Dendrograms are Useful:\n",
    "#     1. Visualizing Cluster Structure:\n",
    "#     2. Identifying Clusters:\n",
    "#     3. Merging and Splitting:\n",
    "#     4. Distance and Similarity:\n",
    "#     5. Cutting the Dendrogram:\n",
    "#     6. Identifying Outliers:\n",
    "#     7. Comparing Clustering Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf70b093-82ca-475f-b6a9-49173b0c9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the\n",
    "# distance metrics different for each type of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7b175c3-d742-4e89-ad97-5082c3dea20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Yes, hierarchical clustering can be used for both numerical and categorical data\n",
    "\n",
    "# Numerical Data: \n",
    "#     Uses distance metrics like Euclidean, Manhattan, and Mahalanobis that handle continuous variables.\n",
    "\n",
    "# Categorical Data: \n",
    "#     Uses distance metrics like Hamming, Jaccard, and Matching Coefficient that handle discrete values and \n",
    "#     measure differences or similarities in categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ea87d3-aaa8-499f-b862-c325fffc4d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa39b487-d342-4781-a8f2-1d31d13421aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering: Helps in identifying outliers by examining the structure of clusters and their distances in the\n",
    "# dendrogram.\n",
    "\n",
    "# Dendrogram: Long branches and small clusters can signal outliers.\n",
    "\n",
    "# Thresholds and Metrics: Setting appropriate thresholds and using distance metrics helps in detecting and validating outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4fc5ba-ad2f-4876-8704-9183cf78edc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f02e9-f022-4313-b818-4d028e8c8e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
